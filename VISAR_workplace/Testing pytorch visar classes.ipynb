{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## pytorch data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:07:20.703246Z",
     "start_time": "2020-02-26T13:07:19.510922Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from visar.dataloader.pytorch_utils import compound_FP_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:07:22.213189Z",
     "start_time": "2020-02-26T13:07:22.206171Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "para_dict = {\n",
    "    'model_name': 'pyDNN_reg',\n",
    "    'task_list': ['T107','T108'],\n",
    "    'eval_type': 'regression',\n",
    "    # input data related params:\n",
    "    'dataset_file': './data/MT_data_clean_June28.csv',\n",
    "    'feature_type': 'Morgan',\n",
    "    'id_field': 'molregno',\n",
    "    'smiles_field': 'salt_removed_smi',\n",
    "    'model_flag': 'MT',\n",
    "    'add_features': None,\n",
    "    'frac_train': 0.8,\n",
    "    'rand_seed': 0,\n",
    "    'batch_size': 100,\n",
    "    # model architecture related parameters:\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:07:46.815986Z",
     "start_time": "2020-02-26T13:07:25.262943Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader, train_df, test_df = compound_FP_loader(para_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:07:50.412043Z",
     "start_time": "2020-02-26T13:07:50.357999Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X, y, w, ids = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:45:48.146570Z",
     "start_time": "2020-02-26T08:45:48.126979Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape, w.shape, len(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T06:43:08.089878Z",
     "start_time": "2020-02-23T06:43:08.083254Z"
    }
   },
   "source": [
    "## pytorch data loader Attentive FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:27:37.095535Z",
     "start_time": "2020-02-26T15:27:35.766647Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from visar.dataloader.AttentiveFP_utils import feature_dict_loader\n",
    "para_dict = {\n",
    "    'model_name': 'Attentive_FP_reg',\n",
    "    'task_list':['T11409', 'T10612'],\n",
    "    # input data related params:\n",
    "    'dataset_file': './data/kinase_sample_data_new_processed.csv',\n",
    "    'feature_file': './data/kinase_sample_data_new.pickle.pickle',\n",
    "    'smiles_field': 'cano_smiles',\n",
    "    'id_field': 'molregno',\n",
    "    'num_atom_features': 39,\n",
    "    'num_bond_features': 10,\n",
    "    'model_flag': 'ST',\n",
    "    'add_features': None,\n",
    "    'frac_train': 0.8,\n",
    "    'rand_seed': 0,\n",
    "    'batch_size': 100,\n",
    "    # model architecture related parameters:\n",
    "    'radius': 2,\n",
    "    'T': 1,\n",
    "    'fingerprint_dim': 128,\n",
    "    'output_units_num': 2,\n",
    "    'dropouts': 0.4,\n",
    "    'batch_normalization': True,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:27:41.535330Z",
     "start_time": "2020-02-26T15:27:40.645208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted dataset shape: (1496, 4)\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, train_df, test_df = feature_dict_loader(para_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:27:43.919142Z",
     "start_time": "2020-02-26T15:27:43.723153Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, w, ids = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:32:02.706991Z",
     "start_time": "2020-02-26T13:32:02.700581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### pytorch DNNx2 regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:07:54.645248Z",
     "start_time": "2020-02-26T13:07:54.638184Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from visar.models.pytorch_models import DNNx2_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:18:03.520581Z",
     "start_time": "2020-02-26T13:18:03.509060Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = DNNx2_regressor(n_features = 2048, layer_nodes = [128, 64, 2], GPU = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:09:24.694981Z",
     "start_time": "2020-02-26T13:09:24.688424Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:18:06.141152Z",
     "start_time": "2020-02-26T13:18:06.135786Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:18:08.255065Z",
     "start_time": "2020-02-26T13:18:08.244091Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(y_pred, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:18:11.121420Z",
     "start_time": "2020-02-26T13:18:11.116284Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out = model.forward4viz(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:18:14.484347Z",
     "start_time": "2020-02-26T13:18:14.475875Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grad = model.get_gradient_task(X, w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:18:26.462692Z",
     "start_time": "2020-02-26T13:18:26.454890Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tv = model.get_transfer_values(X, 2)\n",
    "type(tv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:49:17.896669Z",
     "start_time": "2020-02-26T15:49:17.638515Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import pdb\n",
    "\n",
    "class Fingerprint(nn.Module):\n",
    "\n",
    "    def __init__(self, radius, T, input_feature_dim, input_bond_dim,\\\n",
    "            fingerprint_dim, output_units_num, p_dropout, \n",
    "            batch_normalization = False, momentum = 0.5,GPU = False):\n",
    "        super(Fingerprint, self).__init__()\n",
    "        self.GPU = GPU\n",
    "        self.do_bn = batch_normalization\n",
    "        self.bns = []\n",
    "\n",
    "        # graph attention for atom embedding\n",
    "        atom_fc = nn.Linear(input_feature_dim, fingerprint_dim)\n",
    "        setattr(self, 'fc0', atom_fc)\n",
    "        #self._set_init(atom_fc)\n",
    "        self.atom_fc = atom_fc\n",
    "        if self.do_bn:\n",
    "            bn = nn.BatchNorm1d(fingerprint_dim, momentum = momentum)\n",
    "            setattr(self, 'bn0', bn)\n",
    "            self.bns.append(bn)\n",
    "\n",
    "            bn = nn.BatchNorm2d(fingerprint_dim, momentum = momentum)\n",
    "            setattr(self, 'bn1', bn)\n",
    "            self.bns.append(bn)\n",
    "            \n",
    "            bn = nn.BatchNorm1d(fingerprint_dim, momentum = momentum)\n",
    "            setattr(self, 'bn2', bn)\n",
    "            self.bns.append(bn)\n",
    "            \n",
    "            \n",
    "        self.neighbor_fc = nn.Linear(input_feature_dim+input_bond_dim, fingerprint_dim)\n",
    "        self.GRUCell = nn.ModuleList([nn.GRUCell(fingerprint_dim, fingerprint_dim) for r in range(radius)])\n",
    "        self.align = nn.ModuleList([nn.Linear(2*fingerprint_dim,1) for r in range(radius)])\n",
    "        self.attend = nn.ModuleList([nn.Linear(fingerprint_dim, fingerprint_dim) for r in range(radius)])\n",
    "        # graph attention for molecule embedding\n",
    "        self.mol_GRUCell = nn.GRUCell(fingerprint_dim, fingerprint_dim)\n",
    "        self.mol_align = nn.Linear(2*fingerprint_dim,1)\n",
    "        self.mol_attend = nn.Linear(fingerprint_dim, fingerprint_dim)\n",
    "        # you may alternatively assign a different set of parameter in each attentive layer for molecule embedding like in atom embedding process.\n",
    "#         self.mol_GRUCell = nn.ModuleList([nn.GRUCell(fingerprint_dim, fingerprint_dim) for t in range(T)])\n",
    "#         self.mol_align = nn.ModuleList([nn.Linear(2*fingerprint_dim,1) for t in range(T)])\n",
    "#         self.mol_attend = nn.ModuleList([nn.Linear(fingerprint_dim, fingerprint_dim) for t in range(T)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=p_dropout)\n",
    "        self.output = nn.Linear(fingerprint_dim, output_units_num)\n",
    "\n",
    "        self.radius = radius\n",
    "        self.T = T\n",
    "\n",
    "    def _set_init(self, layer):\n",
    "        init.normal_(layer.weight, mean=0., std=.1) # could be changed here!\n",
    "        init.constant_(layer.bias, 0)\n",
    "\n",
    "    def forward(self, atom_list, bond_list, atom_degree_list, bond_degree_list, atom_mask):\n",
    "        #layer_input = []\n",
    "        #pre_activation = []\n",
    "        \n",
    "        atom_mask = atom_mask.unsqueeze(2)\n",
    "        batch_size,mol_length,num_atom_feat = atom_list.size()\n",
    "        atom_feature_preact = self.atom_fc(atom_list)\n",
    "        \n",
    "        #pre_activation.append(atom_feature_preact)\n",
    "        if self.do_bn: atom_feature_preact = self.bns[0](atom_feature_preact.transpose(1,2)).transpose(1,2) # transpose of the dataset\n",
    "        atom_feature = F.leaky_relu(atom_feature_preact)\n",
    "        #layer_input.append(atom_feature)\n",
    "        bond_neighbor = [bond_list[i][bond_degree_list[i]] for i in range(batch_size)]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        atom_neighbor = [atom_list[i][atom_degree_list[i]] for i in range(batch_size)]\n",
    "        atom_neighbor = torch.stack(atom_neighbor, dim=0)\n",
    "        \n",
    "        # then concatenate them\n",
    "        neighbor_feature = torch.cat([atom_neighbor, bond_neighbor],dim=-1)\n",
    "        neighbor_feature_preact = self.neighbor_fc(neighbor_feature)\n",
    "        #pre_activation.append(neighbor_feature_preact)\n",
    "        if self.do_bn: neighbor_feature_preact = self.bns[1](neighbor_feature_preact.transpose(1,3)).transpose(1,3) # transpose of the dataset\n",
    "        neighbor_feature = F.leaky_relu(neighbor_feature_preact)\n",
    "        #layer_input.append(neighbor_feature)\n",
    "\n",
    "        # generate mask to eliminate the influence of blank atoms\n",
    "        attend_mask = atom_degree_list.clone()\n",
    "        attend_mask[attend_mask != mol_length-1] = 1\n",
    "        attend_mask[attend_mask == mol_length-1] = 0\n",
    "        attend_mask = attend_mask.unsqueeze(-1)\n",
    "        #attend_mask = attend_mask.type(torch.cuda.FloatTensor).unsqueeze(-1)\n",
    "\n",
    "        softmax_mask = atom_degree_list.clone()\n",
    "        softmax_mask[softmax_mask != mol_length-1] = 0\n",
    "        softmax_mask[softmax_mask == mol_length-1] = -9e8 # make the softmax value extremly small\n",
    "        softmax_mask = softmax_mask.unsqueeze(-1)\n",
    "        #softmax_mask = softmax_mask.type(torch.cuda.FloatTensor).unsqueeze(-1)\n",
    "\n",
    "        batch_size, mol_length, max_neighbor_num, fingerprint_dim = neighbor_feature.shape\n",
    "        atom_feature_expand = atom_feature.unsqueeze(-2).expand(batch_size, mol_length, max_neighbor_num, fingerprint_dim)\n",
    "        feature_align = torch.cat([atom_feature_expand, neighbor_feature],dim=-1)\n",
    "        \n",
    "        align_score = F.leaky_relu(self.align[0](self.dropout(feature_align)))\n",
    "#             print(attention_weight)\n",
    "        align_score = align_score + softmax_mask\n",
    "        attention_weight = F.softmax(align_score,-2)\n",
    "#             print(attention_weight)\n",
    "        attention_weight = attention_weight * attend_mask\n",
    "#         print(attention_weight)\n",
    "        neighbor_feature_transform = self.attend[0](self.dropout(neighbor_feature))\n",
    "#             print(features_neighbor_transform.shape)\n",
    "        context = torch.sum(torch.mul(attention_weight,neighbor_feature_transform),-2)\n",
    "#             print(context.shape)\n",
    "        context = F.elu(context)\n",
    "        context_reshape = context.view(batch_size*mol_length, fingerprint_dim)\n",
    "        atom_feature_reshape = atom_feature.view(batch_size*mol_length, fingerprint_dim)\n",
    "        atom_feature_reshape = self.GRUCell[0](context_reshape, atom_feature_reshape)\n",
    "        atom_feature = atom_feature_reshape.view(batch_size, mol_length, fingerprint_dim)\n",
    "\n",
    "        #do nonlinearity\n",
    "        activated_features = F.relu(atom_feature)\n",
    "\n",
    "        for d in range(self.radius-1):\n",
    "            # bonds_indexed = [bond_list[i][torch.cuda.LongTensor(bond_degree_list)[i]] for i in range(batch_size)]\n",
    "            neighbor_feature = [activated_features[i][atom_degree_list[i]] for i in range(batch_size)]\n",
    "            \n",
    "            # neighbor_feature is a list of 3D tensor, so we need to stack them into a 4D tensor first\n",
    "            neighbor_feature = torch.stack(neighbor_feature, dim=0)\n",
    "            atom_feature_expand = activated_features.unsqueeze(-2).expand(batch_size, mol_length, max_neighbor_num, fingerprint_dim)\n",
    "\n",
    "            feature_align = torch.cat([atom_feature_expand, neighbor_feature],dim=-1)\n",
    "\n",
    "            align_score = F.leaky_relu(self.align[d+1](self.dropout(feature_align)))\n",
    "    #             print(attention_weight)\n",
    "            align_score = align_score + softmax_mask\n",
    "            attention_weight = F.softmax(align_score,-2)\n",
    "#             print(attention_weight)\n",
    "            attention_weight = attention_weight * attend_mask\n",
    "#             print(attention_weight)\n",
    "            neighbor_feature_transform = self.attend[d+1](self.dropout(neighbor_feature))\n",
    "    #             print(features_neighbor_transform.shape)\n",
    "            context = torch.sum(torch.mul(attention_weight,neighbor_feature_transform),-2)\n",
    "    #             print(context.shape)\n",
    "            context = F.elu(context)\n",
    "            #layer_input.append(context)\n",
    "            context_reshape = context.view(batch_size*mol_length, fingerprint_dim)\n",
    "#             atom_feature_reshape = atom_feature.view(batch_size*mol_length, fingerprint_dim)\n",
    "            atom_feature_reshape = self.GRUCell[d+1](context_reshape, atom_feature_reshape)\n",
    "            atom_feature = atom_feature_reshape.view(batch_size, mol_length, fingerprint_dim)\n",
    "            \n",
    "            # do nonlinearity\n",
    "            activated_features = F.relu(atom_feature)\n",
    "        \n",
    "        mol_feature = torch.sum(activated_features * atom_mask, dim=-2)\n",
    "        \n",
    "        # do nonlinearity\n",
    "        #pdb.set_trace()\n",
    "        #pre_activation.append(mol_feature)\n",
    "        if self.do_bn: mol_feature = self.bns[2](mol_feature) # transpose of the dataset\n",
    "        activated_features_mol = F.relu(mol_feature)\n",
    "        #layer_input.append(activated_features_mol)\n",
    "        \n",
    "        mol_softmax_mask = atom_mask.clone()\n",
    "        mol_softmax_mask[mol_softmax_mask == 0] = -9e8\n",
    "        mol_softmax_mask[mol_softmax_mask == 1] = 0\n",
    "        #mol_softmax_mask = mol_softmax_mask.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            \n",
    "            mol_prediction_expand = activated_features_mol.unsqueeze(-2).expand(batch_size, mol_length, fingerprint_dim)\n",
    "            mol_align = torch.cat([mol_prediction_expand, activated_features], dim=-1)\n",
    "            mol_align_score = F.leaky_relu(self.mol_align(mol_align))\n",
    "            mol_align_score = mol_align_score + mol_softmax_mask\n",
    "            mol_attention_weight = F.softmax(mol_align_score,-2)\n",
    "            mol_attention_weight = mol_attention_weight * atom_mask\n",
    "#             print(mol_attention_weight.shape,mol_attention_weight)\n",
    "            activated_features_transform = self.mol_attend(self.dropout(activated_features))\n",
    "#             aggregate embeddings of atoms in a molecule\n",
    "            mol_context = torch.sum(torch.mul(mol_attention_weight,activated_features_transform),-2)\n",
    "#             print(mol_context.shape,mol_context)\n",
    "            mol_context = F.elu(mol_context)\n",
    "            mol_feature = self.mol_GRUCell(mol_context, mol_feature)\n",
    "#             print(mol_feature.shape,mol_feature)\n",
    "\n",
    "            # do nonlinearity\n",
    "            activated_features_mol = F.relu(mol_feature)           \n",
    "            \n",
    "        #mol_prediction = F.relu(self.output(self.dropout(mol_feature)))\n",
    "        mol_prediction = self.output(self.dropout(mol_feature))\n",
    "        \n",
    "        return atom_feature, mol_prediction\n",
    "\n",
    "    def forward4viz(self, atom_list, bond_list, atom_degree_list, bond_degree_list, atom_mask):     \n",
    "\n",
    "        atom_mask = atom_mask.unsqueeze(2)\n",
    "        batch_size,mol_length,num_atom_feat = atom_list.size()\n",
    "        atom_feature_preact = self.atom_fc(atom_list)        \n",
    "        if self.do_bn: atom_feature_preact = self.bns[0](atom_feature_preact.transpose(1,2)).transpose(1,2) # transpose of the dataset\n",
    "        atom_feature = F.leaky_relu(atom_feature_preact)\n",
    "\n",
    "        atom_feature_viz = []\n",
    "        atom_feature_viz.append(self.atom_fc(atom_list))\n",
    "\n",
    "        bond_neighbor = [bond_list[i][bond_degree_list[i]] for i in range(batch_size)]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        atom_neighbor = [atom_list[i][atom_degree_list[i]] for i in range(batch_size)]\n",
    "        atom_neighbor = torch.stack(atom_neighbor, dim=0)\n",
    "\n",
    "        #then catenate them\n",
    "        neighbor_feature = torch.cat([atom_neighbor, bond_neighbor],dim=-1)\n",
    "        neighbor_feature_preact = self.neighbor_fc(neighbor_feature)\n",
    "        if self.do_bn: neighbor_feature_preact = self.bns[1](neighbor_feature_preact.transpose(1,3)).transpose(1,3) # transpose of the dataset\n",
    "        neighbor_feature = F.leaky_relu(neighbor_feature_preact)\n",
    "\n",
    "        # generate mask to eliminate the influence of blank atoms\n",
    "        attend_mask = atom_degree_list.clone()\n",
    "        attend_mask[attend_mask != mol_length-1] = 1\n",
    "        attend_mask[attend_mask == mol_length-1] = 0\n",
    "        attend_mask = attend_mask.unsqueeze(-1)\n",
    "        #attend_mask = attend_mask.type(torch.cuda.FloatTensor).unsqueeze(-1)\n",
    "\n",
    "        softmax_mask = atom_degree_list.clone()\n",
    "        softmax_mask[softmax_mask != mol_length-1] = 0\n",
    "        softmax_mask[softmax_mask == mol_length-1] = -9e8 # make the softmax value extremly small\n",
    "        softmax_mask = softmax_mask.unsqueeze(-1)\n",
    "        #softmax_mask = softmax_mask.type(torch.cuda.FloatTensor).unsqueeze(-1)\n",
    "\n",
    "        batch_size, mol_length, max_neighbor_num, fingerprint_dim = neighbor_feature.shape\n",
    "        atom_feature_expand = atom_feature.unsqueeze(-2).expand(batch_size, mol_length, max_neighbor_num, fingerprint_dim)\n",
    "        feature_attention = torch.cat([atom_feature_expand, neighbor_feature],dim=-1)\n",
    "        \n",
    "        align_score = self.dropout(F.leaky_relu(self.align[0](feature_attention)))\n",
    "#             print(attention_weight)\n",
    "        align_score = align_score + softmax_mask\n",
    "        attention_weight = F.softmax(align_score,-2)\n",
    "#             print(attention_weight)\n",
    "        attention_weight = attention_weight * attend_mask\n",
    "#         print(attention_weight)\n",
    "        atom_attention_weight_viz = []\n",
    "        atom_attention_weight_viz.append(attention_weight)\n",
    "        \n",
    "        neighbor_feature_transform = self.attend[0](self.dropout(neighbor_feature))\n",
    "#             print(features_neighbor_transform.shape)\n",
    "        context = torch.sum(torch.mul(attention_weight,neighbor_feature_transform),-2)\n",
    "#             print(context.shape)\n",
    "        context = F.elu(context)\n",
    "        context_reshape = context.view(batch_size*mol_length, fingerprint_dim)\n",
    "        atom_feature_reshape = atom_feature.view(batch_size*mol_length, fingerprint_dim)\n",
    "        atom_feature_reshape = self.GRUCell[0](context_reshape, atom_feature_reshape)\n",
    "        atom_feature = atom_feature_reshape.view(batch_size, mol_length, fingerprint_dim)\n",
    "\n",
    "\n",
    "        #do nonlinearity\n",
    "        activated_features = F.relu(atom_feature)\n",
    "        atom_feature_viz.append(activated_features)\n",
    "\n",
    "        for d in range(self.radius-1):\n",
    "            # bonds_indexed = [bond_list[i][torch.cuda.LongTensor(bond_degree_list)[i]] for i in range(batch_size)]\n",
    "            neighbor_feature = [activated_features[i][atom_degree_list[i]] for i in range(batch_size)]\n",
    "            \n",
    "            # neighbor_feature is a list of 3D tensor, so we need to stack them into a 4D tensor first\n",
    "            neighbor_feature = torch.stack(neighbor_feature, dim=0)\n",
    "            atom_feature_expand = activated_features.unsqueeze(-2).expand(batch_size, mol_length, max_neighbor_num, fingerprint_dim)\n",
    "\n",
    "            feature_attention = torch.cat([atom_feature_expand, neighbor_feature],dim=-1)\n",
    "\n",
    "            align_score = self.dropout(F.leaky_relu(self.align[d+1](feature_attention)))\n",
    "    #             print(attention_weight)\n",
    "            align_score = align_score + softmax_mask\n",
    "            attention_weight = F.softmax(align_score,-2)\n",
    "#             print(attention_weight)\n",
    "            attention_weight = attention_weight * attend_mask\n",
    "            atom_attention_weight_viz.append(attention_weight)\n",
    "#             print(attention_weight)\n",
    "            neighbor_feature_transform = self.attend[d+1](self.dropout(neighbor_feature))\n",
    "    #             print(features_neighbor_transform.shape)\n",
    "            context = torch.sum(torch.mul(attention_weight,neighbor_feature_transform),-2)\n",
    "    #             print(context.shape)\n",
    "            context = F.elu(context)\n",
    "            context_reshape = context.view(batch_size*mol_length, fingerprint_dim)\n",
    "#             atom_feature_reshape = atom_feature.view(batch_size*mol_length, fingerprint_dim)\n",
    "            atom_feature_reshape = self.GRUCell[d+1](context_reshape, atom_feature_reshape)\n",
    "            atom_feature = atom_feature_reshape.view(batch_size, mol_length, fingerprint_dim)\n",
    "            \n",
    "            # do nonlinearity\n",
    "            activated_features = F.relu(atom_feature)\n",
    "            atom_feature_viz.append(activated_features)\n",
    "\n",
    "        # when the descriptor value are unbounded, like partial charge or LogP\n",
    "        mol_feature_unbounded_viz = []\n",
    "        mol_feature_unbounded_viz.append(torch.sum(atom_feature * atom_mask, dim=-2)) \n",
    "        \n",
    "        mol_feature = torch.sum(activated_features * atom_mask, dim=-2)\n",
    "        if self.do_bn: mol_feature = self.bns[2](mol_feature) # transpose of the dataset\n",
    "        activated_features_mol = F.relu(mol_feature)\n",
    "        \n",
    "        # when the descriptor value has lower or upper bounds\n",
    "        mol_feature_viz = []\n",
    "        mol_feature_viz.append(mol_feature) \n",
    "        \n",
    "        mol_attention_weight_viz = []\n",
    "        mol_softmax_mask = atom_mask.clone()\n",
    "        mol_softmax_mask[mol_softmax_mask == 0] = -9e8\n",
    "        mol_softmax_mask[mol_softmax_mask == 1] = 0\n",
    "        #mol_softmax_mask = mol_softmax_mask.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            \n",
    "            mol_prediction_expand = activated_features_mol.unsqueeze(-2).expand(batch_size, mol_length, fingerprint_dim)\n",
    "            mol_align = torch.cat([mol_prediction_expand, activated_features], dim=-1)\n",
    "            mol_align_score = self.dropout(F.leaky_relu(self.mol_align(mol_align)))\n",
    "            mol_align_score = mol_align_score + mol_softmax_mask\n",
    "            mol_attention_weight = F.softmax(mol_align_score,-2)\n",
    "            mol_attention_weight = mol_attention_weight * atom_mask\n",
    "#             print(mol_attention_weight.shape,mol_attention_weight)\n",
    "            mol_attention_weight_viz.append(mol_attention_weight)\n",
    "\n",
    "            activated_features_transform = self.mol_attend(self.dropout(activated_features))\n",
    "            mol_context = torch.sum(torch.mul(mol_attention_weight,activated_features_transform),-2)\n",
    "#             print(mol_context.shape,mol_context)\n",
    "            mol_context = F.elu(mol_context)\n",
    "            mol_feature = self.mol_GRUCell(mol_context, mol_feature)\n",
    "#             print(mol_feature.shape,mol_feature)\n",
    "\n",
    "            mol_feature_unbounded_viz.append(mol_feature)\n",
    "            #do nonlinearity\n",
    "            activated_features_mol = F.relu(mol_feature)           \n",
    "            mol_feature_viz.append(activated_features_mol)\n",
    "            \n",
    "        mol_prediction = self.output(self.dropout(mol_feature))\n",
    "            \n",
    "        return atom_feature_viz, atom_attention_weight_viz, mol_feature_viz, mol_feature_unbounded_viz, mol_attention_weight_viz, mol_prediction\n",
    "\n",
    "    def get_transfer_values(self, x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, n_layer = 0):\n",
    "        _, _, mol_feature_viz, _, _, _ = self.forward4viz(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask)\n",
    "        return mol_feature_viz[n_layer].detach().numpy()\n",
    "\n",
    "    def get_attention_values(self, x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, n_layer = 0):\n",
    "        _, _, _, _, mol_attention_weight_viz, _ = self.forward4viz(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask)\n",
    "        return mol_attention_weight_viz[n_layer].squeeze().detach().numpy()\n",
    "\n",
    "    def predict(self, x_atom, x_bonds, x_atom_index, x_bond_index, x_mask):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            atom_feature, mol_prediction = self.forward(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask)\n",
    "        return atom_feature.numpy(), mol_prediction\n",
    "\n",
    "    def evaluate(self, outputs, values, mask):\n",
    "        outputs = torch.FloatTensor(outputs)\n",
    "            \n",
    "        if len(values.shape) == 1 or values.shape[1] == 1:\n",
    "            y_pred = outputs.flatten()[mask]\n",
    "            y_true = values.flatten()[mask]\n",
    "            \n",
    "            if self.GPU:\n",
    "                y_pred = y_pred.cpu().numpy()\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "            return r2, mse\n",
    "            \n",
    "        else:  # multiple assays\n",
    "            r2_store = []\n",
    "            mse_store = []\n",
    "            for i in range(values.shape[1]):\n",
    "                y_pred = outputs[mask[:,i],i].flatten()\n",
    "                y_true = values[mask[:,i],i].flatten()\n",
    "                if self.GPU:\n",
    "                    y_pred = y_pred.cpu().numpy()\n",
    "                r2_store.append(r2_score(y_true, y_pred))\n",
    "                mse_store.append(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "            print(r2_store)\n",
    "            print(mse_store)\n",
    "\n",
    "            return r2_store, mse_store\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:49:24.022315Z",
     "start_time": "2020-02-26T15:49:24.005756Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Fingerprint(para_dict['radius'], para_dict['T'], \n",
    "                    para_dict['num_atom_features'], para_dict['num_bond_features'],\\\n",
    "                    para_dict['fingerprint_dim'], para_dict['output_units_num'], \n",
    "                    para_dict['dropouts'], \\\n",
    "                    batch_normalization = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:49:34.825049Z",
     "start_time": "2020-02-26T15:49:34.530313Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask = X\n",
    "atom_feature, mol_prediction = model.predict(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:29:05.165279Z",
     "start_time": "2020-02-26T15:29:04.928155Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = model.get_transfer_values(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:45:00.256339Z",
     "start_time": "2020-02-26T15:45:00.032507Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = model.get_attention_values(x_atom, x_bonds, x_atom_index, x_bond_index, x_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T15:49:49.890759Z",
     "start_time": "2020-02-26T15:49:49.883829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fingerprint(\n",
       "  (fc0): Linear(in_features=39, out_features=128, bias=True)\n",
       "  (atom_fc): Linear(in_features=39, out_features=128, bias=True)\n",
       "  (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.5, affine=True, track_running_stats=True)\n",
       "  (neighbor_fc): Linear(in_features=49, out_features=128, bias=True)\n",
       "  (GRUCell): ModuleList(\n",
       "    (0): GRUCell(128, 128)\n",
       "    (1): GRUCell(128, 128)\n",
       "  )\n",
       "  (align): ModuleList(\n",
       "    (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (attend): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (mol_GRUCell): GRUCell(128, 128)\n",
       "  (mol_align): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (mol_attend): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (output): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
